{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aF59-bOyQe_u"
   },
   "source": [
    "### OpenCV DNN 패키지를 이용하여 Faster R-CNN 기반의 Object Detection 수행\n",
    "* Tensorflow 에서 Pretrained 된 모델 파일을 OpenCV에서 로드하여 이미지와 영상에 대한 Object Detection 수행. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tqdm\n",
    "# !pip install opencv-python\n",
    "# !pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReiyE6qXQe_3"
   },
   "source": [
    "#### Tensorflow에서 Pretrained 된 Inference모델(Frozen graph)와 환경파일을 다운로드 받은 후 이를 이용해 OpenCV에서 Inference 모델 생성\n",
    "* https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API 에 다운로드 URL 있음.\n",
    "* pretrained 모델은 http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz 에서 다운로드 후 압축 해제\n",
    "* pretrained 모델을 위한 환경 파일은 https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/faster_rcnn_resnet50_coco_2018_01_28.pbtxt 에서 다운로드 \n",
    "* download된 모델 파일과 config 파일을 인자로 하여 inference 모델을 DNN에서 로딩함. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1X4mTJRhQe_4",
    "outputId": "66620183-6a93-4c24-cce6-52049ce14069"
   },
   "outputs": [],
   "source": [
    "!mkdir ./pretrained\n",
    "!wget -O ./pretrained/faster_rcnn_resnet50_coco_2018_01_28.tar.gz http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz\n",
    "!wget -O ./pretrained/config_graph.pbtxt https://raw.githubusercontent.com/opencv/opencv_extra/master/testdata/dnn/faster_rcnn_resnet50_coco_2018_01_28.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3mn95ff8JuX3",
    "outputId": "d5b32aae-7883-41e3-85da-c7df8de70729"
   },
   "outputs": [],
   "source": [
    "!tar -xvf ./pretrained/faster*.tar.gz -C ./pretrained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r0LFdN3MQe_5",
    "outputId": "8d498a8b-acec-4a43-f513-f9775c9d36ab"
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "!ls -lia ./pretrained/faster_rcnn_resnet50_coco_2018_01_28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZsnnERDQe_7"
   },
   "source": [
    "#### dnn에서 readNetFromTensorflow()로 tensorflow inference 모델을 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yqvx54DBQe_7"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv_net = cv2.dnn.readNetFromTensorflow('./pretrained/faster_rcnn_resnet50_coco_2018_01_28/frozen_inference_graph.pb', \n",
    "                                     './pretrained/config_graph.pbtxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wf_DxJfaQe_9"
   },
   "source": [
    "#### coco 데이터 세트의 클래스id별 클래스명 지정. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VsqWSUnQe__"
   },
   "outputs": [],
   "source": [
    "# OpenCV Tensorflow Faster-RCNN용\n",
    "labels_to_names_0 = {0:'person',1:'bicycle',2:'car',3:'motorcycle',4:'airplane',5:'bus',6:'train',7:'truck',8:'boat',9:'traffic light',\n",
    "                    10:'fire hydrant',11:'street sign',12:'stop sign',13:'parking meter',14:'bench',15:'bird',16:'cat',17:'dog',18:'horse',19:'sheep',\n",
    "                    20:'cow',21:'elephant',22:'bear',23:'zebra',24:'giraffe',25:'hat',26:'backpack',27:'umbrella',28:'shoe',29:'eye glasses',\n",
    "                    30:'handbag',31:'tie',32:'suitcase',33:'frisbee',34:'skis',35:'snowboard',36:'sports ball',37:'kite',38:'baseball bat',39:'baseball glove',\n",
    "                    40:'skateboard',41:'surfboard',42:'tennis racket',43:'bottle',44:'plate',45:'wine glass',46:'cup',47:'fork',48:'knife',49:'spoon',\n",
    "                    50:'bowl',51:'banana',52:'apple',53:'sandwich',54:'orange',55:'broccoli',56:'carrot',57:'hot dog',58:'pizza',59:'donut',\n",
    "                    60:'cake',61:'chair',62:'couch',63:'potted plant',64:'bed',65:'mirror',66:'dining table',67:'window',68:'desk',69:'toilet',\n",
    "                    70:'door',71:'tv',72:'laptop',73:'mouse',74:'remote',75:'keyboard',76:'cell phone',77:'microwave',78:'oven',79:'toaster',\n",
    "                    80:'sink',81:'refrigerator',82:'blender',83:'book',84:'clock',85:'vase',86:'scissors',87:'teddy bear',88:'hair drier',89:'toothbrush',\n",
    "                    90:'hair brush'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fERbvTLUQfAA"
   },
   "source": [
    "#### 이미지를 preprocessing 수행하여 Network에 입력하고 Object Detection 수행 후 결과를 이미지에 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYHEiRKoPKTd",
    "outputId": "f1d98da6-ff10-4bcb-8af3-ac224c5f7cc7"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('./data/sample1.jpg')\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print('image shape:', img.shape)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "y9ELBoueQfAB",
    "outputId": "3562935f-5962-4c41-d43b-3906380c5485"
   },
   "outputs": [],
   "source": [
    "# 원본 이미지가 Faster RCNN기반 네트웍으로 입력 시 resize됨. \n",
    "# scaling된 이미지 기반으로 bounding box 위치가 예측 되므로 이를 다시 원복하기 위해 원본 이미지 shape정보 필요\n",
    "rows = img.shape[0]\n",
    "cols = img.shape[1]\n",
    "# cv2의 rectangle()은 인자로 들어온 이미지 배열에 직접 사각형을 업데이트 하므로 그림 표현을 위한 별도의 이미지 배열 생성. \n",
    "draw_img = img.copy()\n",
    "\n",
    "# 원본 이미지 배열 BGR을 RGB로 변환하여 배열 입력. Tensorflow Faster RCNN은 마지막 classification layer가 Dense가 아니여서 size를 고정할 필요는 없음.  \n",
    "cv_net.setInput(cv2.dnn.blobFromImage(img, swapRB=True, crop=False))\n",
    "\n",
    "# Object Detection 수행하여 결과를 cvOut으로 반환 \n",
    "cv_out = cv_net.forward()\n",
    "print(cv_out.shape)\n",
    "\n",
    "# bounding box의 테두리와 caption 글자색 지정\n",
    "green_color=(0, 255, 0)\n",
    "red_color=(0, 0, 255)\n",
    "\n",
    "# detected 된 object들을 iteration 하면서 정보 추출\n",
    "for detection in cv_out[0,0,:,:]:\n",
    "    score = float(detection[2])\n",
    "    class_id = int(detection[1])\n",
    "    # detected된 object들의 score가 0.5 이상만 추출\n",
    "    if score > 0.5:\n",
    "        # detected된 object들은 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n",
    "        left = detection[3] * cols\n",
    "        top = detection[4] * rows\n",
    "        right = detection[5] * cols\n",
    "        bottom = detection[6] * rows\n",
    "        # labels_to_names_seq 딕셔너리로 class_id값을 클래스명으로 변경.\n",
    "        caption = \"{}: {:.4f}\".format(labels_to_names_0[class_id], score)\n",
    "        print(caption)\n",
    "        #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n",
    "        cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n",
    "        cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.4, red_color, 1)\n",
    "\n",
    "img_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTuFb6bqQfAB"
   },
   "source": [
    "#### 단일 이미지의 object detection을 함수로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdrQAwxYQfAC"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_detected_img(cv_net, img_array, score_threshold, use_copied_array=True, is_print=True):\n",
    "    \n",
    "    rows = img_array.shape[0]\n",
    "    cols = img_array.shape[1]\n",
    "    \n",
    "    draw_img = None\n",
    "    if use_copied_array:\n",
    "        draw_img = img_array.copy()\n",
    "    else:\n",
    "        draw_img = img_array\n",
    "    \n",
    "    cv_net.setInput(cv2.dnn.blobFromImage(img_array, swapRB=True, crop=False))\n",
    "    \n",
    "    start = time.time()\n",
    "    cv_out = cv_net.forward()\n",
    "    \n",
    "    green_color=(0, 255, 0)\n",
    "    red_color=(0, 0, 255)\n",
    "\n",
    "    # detected 된 object들을 iteration 하면서 정보 추출\n",
    "    for detection in cv_out[0,0,:,:]:\n",
    "        score = float(detection[2])\n",
    "        class_id = int(detection[1])\n",
    "        # detected된 object들의 score가 함수 인자로 들어온 score_threshold 이상만 추출\n",
    "        if score > score_threshold:\n",
    "            # detected된 object들은 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n",
    "            left = detection[3] * cols\n",
    "            top = detection[4] * rows\n",
    "            right = detection[5] * cols\n",
    "            bottom = detection[6] * rows\n",
    "            # labels_to_names 딕셔너리로 class_id값을 클래스명으로 변경. opencv에서는 class_id + 1로 매핑해야함.\n",
    "            caption = \"{}: {:.4f}\".format(labels_to_names_0[class_id], score)\n",
    "            # print(caption)\n",
    "            #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n",
    "            cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n",
    "            cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.4, red_color, 1)\n",
    "    if is_print:\n",
    "        print('Detection 수행시간:',round(time.time() - start, 2),\"초\")\n",
    "\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "id": "c7YH7nFDQfAC",
    "outputId": "aa669702-352f-48e9-b54f-251e95d3b552"
   },
   "outputs": [],
   "source": [
    "# image 로드 \n",
    "img = cv2.imread('./data/sample1.jpg')\n",
    "print('image shape:', img.shape)\n",
    "\n",
    "# tensorflow inference 모델 로딩\n",
    "cv_net = cv2.dnn.readNetFromTensorflow('./pretrained/faster_rcnn_resnet50_coco_2018_01_28/frozen_inference_graph.pb', \n",
    "                                     './pretrained/config_graph.pbtxt')\n",
    "# Object Detetion 수행 후 시각화 \n",
    "draw_img = get_detected_img(cv_net, img, score_threshold=0.5, use_copied_array=True, is_print=True)\n",
    "\n",
    "img_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 940
    },
    "id": "3Je3_OPIQfAD",
    "outputId": "42843a72-6fad-4d68-85bb-24f5fb755f2d"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/sample2.jpg')\n",
    "print('image shape:', img.shape)\n",
    "\n",
    "# tensorflow inference 모델 로딩\n",
    "cv_net = cv2.dnn.readNetFromTensorflow('./pretrained/faster_rcnn_resnet50_coco_2018_01_28/frozen_inference_graph.pb', \n",
    "                                     './pretrained/config_graph.pbtxt')\n",
    "# Object Detetion 수행 후 시각화 \n",
    "draw_img = get_detected_img(cv_net, img, score_threshold=0.5, use_copied_array=True, is_print=True)\n",
    "\n",
    "img_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCj2eqYjQfAE"
   },
   "source": [
    "### Video Object Detection 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9dnZWC3QfAE"
   },
   "source": [
    "#### VideoCapture와 VideoWriter 설정하기\n",
    "* VideoCapture를 이용하여 Video를 frame별로 capture 할 수 있도록 설정\n",
    "* VideoCapture의 속성을 이용하여 Video Frame의 크기 및 FPS 설정. \n",
    "* VideoWriter를 위한 인코딩 코덱 설정 및 영상 write를 위한 설정 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9jXeIBrQfAG"
   },
   "source": [
    "#### video detection 적용 후 재생 함수 생성. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "def do_detected_play(cv_net, input_path, score_threshold, is_print):\n",
    "    \n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print('총 Frame 갯수:', frame_cnt)\n",
    "\n",
    "    green_color=(0, 255, 0)\n",
    "    red_color=(0, 0, 255)\n",
    "    while True:\n",
    "        hasFrame, img_frame = cap.read()\n",
    "        if not hasFrame:\n",
    "            print('더 이상 처리할 frame이 없습니다.')\n",
    "            break\n",
    "        \n",
    "        img_frame = get_detected_img(cv_net, img_frame, score_threshold=score_threshold, use_copied_array=False, is_print=is_print)\n",
    "        clone = img_frame.copy()\n",
    "        clone = cv2.cvtColor(clone, cv2.COLOR_BGR2RGB)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(Image.fromarray(clone))\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_detected_play(cv_net, './data/ant.mp4', 0.5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동영상 파일로 저장 후 재생 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt update\n",
    "# !apt install -y build-essential cmake git python3-dev python3-numpy \\\n",
    "# libavcodec-dev libavformat-dev libswscale-dev \\\n",
    "# libgstreamer-plugins-base1.0-dev \\\n",
    "# libgstreamer1.0-dev libgtk-3-dev \\\n",
    "# libpng-dev libjpeg-dev libopenexr-dev libtiff-dev libwebp-dev \\\n",
    "# libopencv-dev x264 libx264-dev libssl-dev ffmpeg\n",
    "# !pip uninstall -y opencv-python\n",
    "# avc1 코덱을 사용하려면 binary 버전의 opencv-python을 삭제하고 소스로 다시 설치 해야함\n",
    "# !pip install --no-binary opencv-python opencv-python\n",
    "# 커널 재시작 해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKONgteuQfAH"
   },
   "outputs": [],
   "source": [
    "from tqdm import notebook\n",
    "\n",
    "def do_detected_video(cv_net, input_path, output_path, score_threshold, is_print):\n",
    "    \n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "\n",
    "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size) \n",
    "\n",
    "    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print('총 Frame 갯수:', frame_cnt)\n",
    "\n",
    "    green_color=(0, 255, 0)\n",
    "    red_color=(0, 0, 255)\n",
    "    for i in notebook.tqdm(range(frame_cnt)):\n",
    "        hasFrame, img_frame = cap.read()\n",
    "        if not hasFrame:\n",
    "            print('더 이상 처리할 frame이 없습니다.')\n",
    "            break\n",
    "        \n",
    "        img_frame = get_detected_img(cv_net, img_frame, score_threshold=score_threshold, use_copied_array=False, is_print=is_print)\n",
    "        vid_writer.write(img_frame)\n",
    "\n",
    "    vid_writer.release()\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mzwyzcNzQfAH",
    "outputId": "2e26143d-af92-4a95-d0ed-1ae900907480"
   },
   "outputs": [],
   "source": [
    "do_detected_video(cv_net, './data/ant.mp4', './data/ant_detected.mp4', 0.5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Video\n",
    "\n",
    "# Video(\"./data/ant_detected.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
