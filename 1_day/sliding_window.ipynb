{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 슬라이딩 윈도우 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.2.0\n",
    "!pip install imutils\n",
    "!pip install opencv-python\n",
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코드 zip 파일 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/classifier-to-detector/classifier-to-detector.zip\n",
    "!unzip -qq classifier-to-detector.zip\n",
    "%cd classifier-to-detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패키지 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from pyimagesearch.detection_helpers import sliding_window\n",
    "from pyimagesearch.detection_helpers import image_pyramid\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jupyter notebook 에서 이미지 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_imshow(title, image):\n",
    "    # convert the image frame BGR to RGB color space and display it\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.grid(False)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"images/stingray.jpg\")\n",
    "# print(type(image))\n",
    "# print(image.shape)\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(image)\n",
    "# plt.grid(False)\n",
    "# plt.title(\"stingray\")\n",
    "# plt.show()\n",
    "plt_imshow(\"stingray\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 피라미드 및 슬라이딩 윈도우 유틸리티 기능 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2 \n",
    "import IPython.display as display\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(\"images/stingray.jpg\")\n",
    "\n",
    "# Define the window size\n",
    "window_size = (64, 64)\n",
    "\n",
    "# Define the step size\n",
    "step_size = (8, 8)\n",
    "\n",
    "# Define how many steps to take in x and y directions\n",
    "x_steps = np.arange(0, image.shape[1] - window_size[1], step_size[0])\n",
    "y_steps = np.arange(0, image.shape[0] - window_size[0], step_size[1])\n",
    "# print(x_steps)\n",
    "# print(y_steps)\n",
    "for y in y_steps:\n",
    "    for x in x_steps:\n",
    "        # Extract the window from the image\n",
    "        window = image[y:y + window_size[1], x:x + window_size[0]]\n",
    "\n",
    "        clone = image.copy()\n",
    "        # Here is where you would add your object detection code. \n",
    "        # For now we will just draw a rectangle around the window.\n",
    "        cv2.rectangle(clone, (x, y), (x + window_size[0], y + window_size[1]), (255, 0, 0), 2)\n",
    "#         plt_imshow(\"stingray\", clone)\n",
    "        clone = cv2.cvtColor(clone, cv2.COLOR_BGR2RGB)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(Image.fromarray(clone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo():\n",
    "    print(\"foo()\")\n",
    "    y=0\n",
    "    for x in range(0, 30, 8):\n",
    "        yield x,y\n",
    "    \n",
    "g = foo()\n",
    "print(g)\n",
    "# ret = next(g)\n",
    "# print(ret)\n",
    "# ret = next(g)\n",
    "# print(ret)\n",
    "# ret = next(g)\n",
    "# print(ret)\n",
    "# ret = next(g)\n",
    "# print(ret)\n",
    "# ret = next(g)\n",
    "# print(ret)\n",
    "for elem in g:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, step, ws):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0] - ws[1], step):\n",
    "        for x in range(0, image.shape[1] - ws[0], step):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + ws[1], x:x + ws[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2 \n",
    "import IPython.display as display\n",
    "\n",
    "# Load your image\n",
    "image = cv2.imread(\"images/stingray.jpg\")\n",
    "\n",
    "# Define window size and step size\n",
    "window_size = (64, 64)  # (width, height)\n",
    "step_size = 8\n",
    "\n",
    "# Iterate through the sliding windows\n",
    "for (x, y, window) in sliding_window(image, step_size, window_size):\n",
    "    if window.shape[0] != window_size[1] or window.shape[1] != window_size[0]:\n",
    "        continue\n",
    "\n",
    "    # Optionally, visualize the sliding windows\n",
    "    clone = image.copy()\n",
    "    cv2.rectangle(clone, (x, y), (x + window_size[0], y + window_size[1]), (0, 255, 0), 2)\n",
    "    clone = cv2.cvtColor(clone, cv2.COLOR_BGR2RGB)\n",
    "#     plt_imshow(\"aaa\", clone)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(Image.fromarray(clone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pyramid(image, scale=1.5, minSize=(128, 128)):\n",
    "    # yield the original image\n",
    "    yield image\n",
    "\n",
    "    # keep looping over the image pyramid\n",
    "    while True:\n",
    "        # compute the dimensions of the next image in the pyramid\n",
    "        w = int(image.shape[1] / scale)\n",
    "        image = imutils.resize(image, width=w)\n",
    "\n",
    "        # if the resized image does not meet the supplied minimum\n",
    "        # size, then stop constructing the pyramid\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break\n",
    "\n",
    "        # yield the next image in the pyramid\n",
    "        yield image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"images/stingray.jpg\")\n",
    "for im in image_pyramid(image):\n",
    "    print(im.shape)\n",
    "    plt_imshow(\"stingray\", im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전 학습된 이미지 분류자를 객체 감지기로 전환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = '(10,20)'\n",
    "print(eval(value)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python  sliding_window.py --image images/stingray.jpg --size (300, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"image\": \"images/stingray.jpg\",\n",
    "    \"size\": \"(300, 150)\",\n",
    "    \"min_conf\": 0.9,\n",
    "    \"visualize\": 1\n",
    "}\n",
    "# eval(args[\"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables used for the object detection procedure\n",
    "WIDTH = 600\n",
    "PYR_SCALE = 1.5\n",
    "WIN_STEP = 16\n",
    "ROI_SIZE = eval(args[\"size\"])\n",
    "INPUT_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our network weights from disk\n",
    "print(\"[INFO] loading network...\")\n",
    "model = ResNet50(weights=\"imagenet\", include_top=True)\n",
    "# model.summary()\n",
    "# orig = cv2.imread(args[\"image\"])\n",
    "# orig = imutils.resize(orig, width=WIDTH)\n",
    "# print(orig.shape)\n",
    "# (H, W) = orig.shape[:2]\n",
    "# print(H, W)\n",
    "\n",
    "\n",
    "# load the input image from disk, resize it such that it has the\n",
    "# has the supplied width, and then grab its dimensions\n",
    "orig = cv2.imread(args[\"image\"])\n",
    "print(orig.shape)\n",
    "orig = imutils.resize(orig, width=WIDTH)\n",
    "(H, W) = orig.shape[:2]\n",
    "print((H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the image pyramid\n",
    "pyramid = image_pyramid(orig, scale=PYR_SCALE, minSize=ROI_SIZE)\n",
    "\n",
    "# initialize two lists, one to hold the ROIs generated from the image\n",
    "# pyramid and sliding window, and another list used to store the\n",
    "# (x, y)-coordinates of where the ROI was in the original image\n",
    "rois = []\n",
    "locs = []\n",
    "\n",
    "# time how long it takes to loop over the image pyramid layers and\n",
    "# sliding window locations\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the image pyramid\n",
    "for image in pyramid:\n",
    "    # determine the scale factor between the *original* image\n",
    "    # dimensions and the *current* layer of the pyramid\n",
    "    scale = W / float(image.shape[1])\n",
    "\n",
    "    # for each layer of the image pyramid, loop over the sliding\n",
    "    # window locations\n",
    "    for (x, y, roiOrig) in sliding_window(image, WIN_STEP, ROI_SIZE):\n",
    "        # scale the (x, y)-coordinates of the ROI with respect to the\n",
    "        # *original* image dimensions\n",
    "        x = int(x * scale)\n",
    "        y = int(y * scale)\n",
    "        w = int(ROI_SIZE[0] * scale)\n",
    "        h = int(ROI_SIZE[1] * scale)\n",
    "\n",
    "        # take the ROI and preprocess it so we can later classify\n",
    "        # the region using Keras/TensorFlow\n",
    "        roi = cv2.resize(roiOrig, INPUT_SIZE)\n",
    "        roi = img_to_array(roi)\n",
    "        roi = preprocess_input(roi)\n",
    "\n",
    "        # update our list of ROIs and associated coordinates\n",
    "        rois.append(roi)\n",
    "        locs.append((x, y, x + w, y + h))\n",
    "\n",
    "        # check to see if we are visualizing each of the sliding\n",
    "        # windows in the image pyramid\n",
    "        if args[\"visualize\"] > 0:\n",
    "            # clone the original image and then draw a bounding box\n",
    "            # surrounding the current region\n",
    "            clone = orig.copy()\n",
    "            cv2.rectangle(clone, (x, y), (x + w, y + h),\n",
    "                (0, 255, 0), 2)\n",
    "\n",
    "            # show the visualization and current ROI\n",
    "            plt_imshow(\"Visualization\", clone)\n",
    "            plt_imshow(\"ROI\", roiOrig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show how long it took to loop over the image pyramid layers and\n",
    "# sliding window locations\n",
    "end = time.time()\n",
    "print(\"[INFO] looping over pyramid/windows took {:.5f} seconds\".format(\n",
    "    end - start))\n",
    "\n",
    "# convert the ROIs to a NumPy array\n",
    "rois = np.array(rois, dtype=\"float32\")\n",
    "print(rois.shape)\n",
    "\n",
    "# classify each of the proposal ROIs using ResNet and then show how\n",
    "# long the classifications took\n",
    "print(\"[INFO] classifying ROIs...\")\n",
    "start = time.time()\n",
    "preds = model.predict(rois)\n",
    "end = time.time()\n",
    "print(\"[INFO] classifying ROIs took {:.5f} seconds\".format(\n",
    "    end - start))\n",
    "\n",
    "print(preds.shape) #(360,)\n",
    "# print(preds)\n",
    "\n",
    "# decode the predictions and initialize a dictionary which maps class\n",
    "# labels (keys) to any ROIs associated with that label (values)\n",
    "preds = imagenet_utils.decode_predictions(preds, top=1)\n",
    "print(preds)\n",
    "labels = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the predictions\n",
    "for (i, p) in enumerate(preds):\n",
    "#     print(i, p)\n",
    "#     break\n",
    "    # grab the prediction information for the current ROI\n",
    "    (imagenetID, label, prob) = p[0]\n",
    "\n",
    "    # filter out weak detections by ensuring the predicted probability\n",
    "    # is greater than the minimum probability\n",
    "    if prob >= args[\"min_conf\"]:\n",
    "        # grab the bounding box associated with the prediction and\n",
    "        # convert the coordinates\n",
    "        box = locs[i]\n",
    "\n",
    "        # grab the list of predictions for the label and add the\n",
    "        # bounding box and probability to the list\n",
    "        L = labels.get(label, [])\n",
    "#         print(L)\n",
    "        L.append((box, prob))\n",
    "#         print(L)\n",
    "        labels[label] = L\n",
    "#         print(labels)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the labels for each of detected objects in the image\n",
    "for label in labels.keys():\n",
    "    # clone the original image so that we can draw on it\n",
    "    print(\"[INFO] showing results for '{}'\".format(label))\n",
    "    clone = orig.copy()\n",
    "\n",
    "    # loop over all bounding boxes for the current label\n",
    "    for (box, prob) in labels[label]:\n",
    "        # draw the bounding box on the image\n",
    "        (startX, startY, endX, endY) = box\n",
    "        cv2.rectangle(clone, (startX, startY), (endX, endY),\n",
    "            (0, 255, 0), 2)\n",
    "\n",
    "    # show the results *before* applying non-maxima suppression, then\n",
    "    # clone the image again so we can display the results *after*\n",
    "    # applying non-maxima suppression\n",
    "    plt_imshow(\"Before\", clone)\n",
    "    clone = orig.copy()\n",
    "\n",
    "    # extract the bounding boxes and associated prediction\n",
    "    # probabilities, then apply non-maxima suppression\n",
    "    boxes = np.array([p[0] for p in labels[label]])\n",
    "    proba = np.array([p[1] for p in labels[label]])\n",
    "    boxes = non_max_suppression(boxes, proba)\n",
    "\n",
    "    # loop over all bounding boxes that were kept after applying\n",
    "    # non-maxima suppression\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        # draw the bounding box and label on the image\n",
    "        cv2.rectangle(clone, (startX, startY), (endX, endY),\n",
    "            (0, 255, 0), 2)\n",
    "        y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "        cv2.putText(clone, label, (startX, y),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "\n",
    "    # show the output after apply non-maxima suppression\n",
    "    plt_imshow(\"After\", clone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
