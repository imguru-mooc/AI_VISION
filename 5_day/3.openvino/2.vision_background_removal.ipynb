{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "93aa099e",
      "metadata": {
        "id": "93aa099e"
      },
      "source": [
        "# U^2-Net 및 OpenVINO™를 사용한 이미지 배경 제거\n",
        "\n",
        "이 노트북은 U$^2$-Net 및 OpenVINO를 사용하여 이미지에서 배경 제거를 보여줍니다.\n",
        "\n",
        "소스 코드 및 테스트 데이터를 포함하여 U$^2$-Net에 대한 자세한 내용은 [GitHub 페이지](https://github.com/xuebinqin/U-2-Net) 및 연구 논문: [U^ 2-Net: 핵심 개체 감지를 위한 중첩된 U 구조를 통한 심층 분석](https://arxiv.org/pdf/2005.09007.pdf).\n",
        "\n",
        "PyTorch U$^2$-Net 모델은 OpenVINO IR 형식으로 변환됩니다. 모델 소스는 [여기](https://github.com/xuebinqin/U-2-Net)에서 확인할 수 있습니다.\n",
        "\n",
        "#### 내용의 테이블:\n",
        "- [준비](#준비-위화살표)\n",
        "     - [설치 요구 사항](#Install-requirements-Uparrow)\n",
        "     - [PyTorch 라이브러리 및 U$^2$-Net 가져오기](#Import-the-PyTorch-Library-and-U2-Net-Uparrow)\n",
        "     - [설정](#설정-위쪽 화살표)\n",
        "     - [U$^2$-Net 모델 로드](#Load-the-U2-Net-Model-Uparrow)\n",
        "- [PyTorch U$^2$-Net 모델을 OpenVINO IR로 변환](#Convert-PyTorch-U2-Net-model-to-OpenVINO-IR-Uparrow)\n",
        "     - [Pytorch 모델을 OpenVINO IR 형식으로 변환](#Convert-Pytorch-model-to-OpenVINO-IR-Format-Uparrow)\n",
        "- [입력 이미지 로드 및 전처리](#Load-and-Pre-Process-Input-Image-Uparrow)\n",
        "- [추론 장치 선택](#Select-inference-device-Uparrow)\n",
        "- [OpenVINO IR 모델에서 추론 수행](#Do-Inference-on-OpenVINO-IR-Model-Uparrow)\n",
        "- [결과 시각화](#Visualize-Results-Uparrow)\n",
        "     - [배경 이미지 추가](#Add-a-Background-Image-Uparrow)\n",
        "- [참고자료](#References-Uparrow)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e57b48f0",
      "metadata": {
        "tags": [
          "hide"
        ],
        "id": "e57b48f0"
      },
      "source": [
        "## 준비 [$\\Uparrow$](#목차:)\n",
        "\n",
        "### 설치 요구 사항 [$\\Uparrow$](#목차:)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "513b6331",
      "metadata": {
        "id": "513b6331"
      },
      "outputs": [],
      "source": [
        "%pip install -q \"openvino>=2023.1.0\"\n",
        "%pip install -q torch opencv-python matplotlib\n",
        "%pip install -q gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e89b0bd",
      "metadata": {
        "id": "0e89b0bd"
      },
      "source": [
        "### PyTorch 라이브러리 및 U$^2$-Net [$\\Uparrow$](#목차:) 가져오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8124fd11",
      "metadata": {
        "id": "8124fd11"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import sys\n",
        "from collections import namedtuple\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import openvino as ov\n",
        "import torch\n",
        "from IPython.display import HTML, FileLink, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57edabfb",
      "metadata": {
        "id": "57edabfb"
      },
      "outputs": [],
      "source": [
        "# Import local modules\n",
        "\n",
        "utils_file_path = Path(\"../utils/notebook_utils.py\")\n",
        "notebook_directory_path = Path(\".\")\n",
        "\n",
        "if not utils_file_path.exists():\n",
        "    !git clone --depth 1 https://github.com/openvinotoolkit/openvino_notebooks.git\n",
        "    utils_file_path = Path(\"./openvino_notebooks/notebooks/utils/notebook_utils.py\")\n",
        "    notebook_directory_path = Path(\"./openvino_notebooks/notebooks/205-vision-background-removal/\")\n",
        "\n",
        "sys.path.append(str(utils_file_path.parent))\n",
        "sys.path.append(str(notebook_directory_path))\n",
        "\n",
        "from notebook_utils import load_image\n",
        "from model.u2net import U2NET, U2NETP"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bae3e45",
      "metadata": {
        "tags": [
          "hide"
        ],
        "id": "0bae3e45"
      },
      "source": [
        "### 설정 [$\\Uparrow$](#목차:)\n",
        "\n",
        "이 튜토리얼에서는 원래의 U$^2$-Net 핵심 개체 감지 모델과 더 작은 U2NETP 버전의 사용을 지원합니다. 원래 모델에는 주요 객체 감지와 인간 분할이라는 두 가지 가중치 세트가 지원됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e9c87b8",
      "metadata": {
        "id": "7e9c87b8"
      },
      "outputs": [],
      "source": [
        "model_config = namedtuple(\"ModelConfig\", [\"name\", \"url\", \"model\", \"model_args\"])\n",
        "\n",
        "u2net_lite = model_config(\n",
        "    name=\"u2net_lite\",\n",
        "    url=\"https://drive.google.com/uc?id=1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy\",\n",
        "    model=U2NETP,\n",
        "    model_args=(),\n",
        ")\n",
        "u2net = model_config(\n",
        "    name=\"u2net\",\n",
        "    url=\"https://drive.google.com/uc?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ\",\n",
        "    model=U2NET,\n",
        "    model_args=(3, 1),\n",
        ")\n",
        "u2net_human_seg = model_config(\n",
        "    name=\"u2net_human_seg\",\n",
        "    url=\"https://drive.google.com/uc?id=1-Yg0cxgrNhHP-016FPdp902BR-kSsA4P\",\n",
        "    model=U2NET,\n",
        "    model_args=(3, 1),\n",
        ")\n",
        "\n",
        "# Set u2net_model to one of the three configurations listed above.\n",
        "u2net_model = u2net_lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7799f33c",
      "metadata": {
        "tags": [
          "hide_output",
          "hide"
        ],
        "id": "7799f33c"
      },
      "outputs": [],
      "source": [
        "# The filenames of the downloaded and converted models.\n",
        "MODEL_DIR = \"model\"\n",
        "model_path = Path(MODEL_DIR) / u2net_model.name / Path(u2net_model.name).with_suffix(\".pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8522caea",
      "metadata": {
        "id": "8522caea",
        "tags": [
          "hide"
        ]
      },
      "source": [
        "### U$^2$-Net 모델 로드 [$\\Uparrow$](#목차:)\n",
        "\n",
        "U$^2$-Net 인간 분할 모델 가중치는 Google 드라이브에 저장됩니다. 아직 존재하지 않으면 다운로드됩니다. 다음 셀은 모델과 사전 훈련된 가중치를 로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eae9467",
      "metadata": {
        "tags": [
          "hide"
        ],
        "id": "0eae9467"
      },
      "outputs": [],
      "source": [
        "if not model_path.exists():\n",
        "    import gdown\n",
        "\n",
        "    os.makedirs(name=model_path.parent, exist_ok=True)\n",
        "    print(\"Start downloading model weights file... \")\n",
        "    with open(model_path, \"wb\") as model_file:\n",
        "        gdown.download(url=u2net_model.url, output=model_file)\n",
        "        print(f\"Model weights have been downloaded to {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f0fb802",
      "metadata": {
        "tags": [
          "hide"
        ],
        "id": "6f0fb802"
      },
      "outputs": [],
      "source": [
        "# Load the model.\n",
        "net = u2net_model.model(*u2net_model.model_args)\n",
        "net.eval()\n",
        "\n",
        "# Load the weights.\n",
        "print(f\"Loading model weights from: '{model_path}'\")\n",
        "net.load_state_dict(state_dict=torch.load(model_path, map_location=\"cpu\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45d55f18",
      "metadata": {
        "id": "45d55f18",
        "tags": [
          "hide"
        ]
      },
      "source": [
        "## PyTorch U$^2$-Net 모델을 OpenVINO IR로 변환 [$\\Uparrow$](#목차:)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "960b0c2f",
      "metadata": {
        "id": "960b0c2f",
        "tags": [
          "hide"
        ]
      },
      "source": [
        "모델 변환 Python API를 사용하여 Pytorch 모델을 OpenVINO IR 형식으로 변환합니다.\n",
        "다음 명령을 실행하는 데 시간이 걸릴 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba3a505",
      "metadata": {
        "id": "1ba3a505"
      },
      "outputs": [],
      "source": [
        "model_ir = ov.convert_model(net, example_input=torch.zeros((1,3,512,512)), input=([1, 3, 512, 512]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43ed7603",
      "metadata": {
        "id": "43ed7603",
        "tags": [
          "hide"
        ]
      },
      "source": [
        "## 입력 이미지 로드 및 전처리 [$\\Uparrow$](#목차:)\n",
        "\n",
        "OpenCV는 'BGR' 형식의 이미지를 읽는 반면, OpenVINO IR 모델은 'RGB'의 이미지를 기대합니다. 따라서 이미지를 'RGB'로 변환하고 '512 x 512'로 크기를 조정한 다음 OpenVINO IR 모델이 예상하는 형식으로 크기를 바꿉니다.\n",
        "\n",
        "이미지 텐서에 평균값을 추가하고 표준편차로 입력의 크기를 조정합니다. 이를 네트워크를 통해 전파하기 전에 입력 데이터 정규화라고 합니다. 평균 및 표준 편차 값은 [U^2-Net 저장소]의 [dataloader](https://github.com/xuebinqin/U-2-Net/blob/master/data_loader.py) 파일에서 확인할 수 있습니다. (https://github.com/xuebinqin/U-2-Net/) 0-255의 픽셀 값을 가진 이미지를 지원하기 위해 255를 곱합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a86e7fd",
      "metadata": {
        "id": "1a86e7fd",
        "tags": [
          "hide"
        ]
      },
      "outputs": [],
      "source": [
        "IMAGE_URI = \"https://storage.openvinotoolkit.org/repositories/openvino_notebooks/data/data/image/coco_hollywood.jpg\"\n",
        "\n",
        "input_mean = np.array([123.675, 116.28 , 103.53]).reshape(1, 3, 1, 1)\n",
        "input_scale = np.array([58.395, 57.12 , 57.375]).reshape(1, 3, 1, 1)\n",
        "\n",
        "image = cv2.cvtColor(\n",
        "    src=load_image(IMAGE_URI),\n",
        "    code=cv2.COLOR_BGR2RGB,\n",
        ")\n",
        "\n",
        "resized_image = cv2.resize(src=image, dsize=(512, 512))\n",
        "# Convert the image shape to a shape and a data type expected by the network\n",
        "# for OpenVINO IR model: (1, 3, 512, 512).\n",
        "input_image = np.expand_dims(np.transpose(resized_image, (2, 0, 1)), 0)\n",
        "\n",
        "input_image = (input_image - input_mean) / input_scale"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b86340b-3e3f-4f46-83ef-4b5b40cf9053",
      "metadata": {
        "id": "8b86340b-3e3f-4f46-83ef-4b5b40cf9053"
      },
      "source": [
        "## 추론 장치 선택 [$\\Uparrow$](#목차:)\n",
        "\n",
        "OpenVINO를 사용하여 추론을 실행하려면 드롭다운 목록에서 장치를 선택하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f19e743-1491-434f-a663-4b9d67ab2701",
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "0f19e743-1491-434f-a663-4b9d67ab2701"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "core = ov.Core()\n",
        "device = widgets.Dropdown(\n",
        "    options=core.available_devices + [\"AUTO\"],\n",
        "    value='AUTO',\n",
        "    description='Device:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae10f73a",
      "metadata": {
        "id": "ae10f73a",
        "tags": [
          "hide"
        ]
      },
      "source": [
        "## OpenVINO IR 모델에 대한 추론 수행 [$\\Uparrow$](#목차:)\n",
        "\n",
        "OpenVINO IR 모델을 OpenVINO Runtime에 로드하고 추론을 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6cff378",
      "metadata": {
        "id": "a6cff378",
        "tags": [
          "hide"
        ]
      },
      "outputs": [],
      "source": [
        "core = ov.Core()\n",
        "# Load the network to OpenVINO Runtime.\n",
        "compiled_model_ir = core.compile_model(model=model_ir, device_name=device.value)\n",
        "# Get the names of input and output layers.\n",
        "input_layer_ir = compiled_model_ir.input(0)\n",
        "output_layer_ir = compiled_model_ir.output(0)\n",
        "\n",
        "# Do inference on the input image.\n",
        "start_time = time.perf_counter()\n",
        "result = compiled_model_ir([input_image])[output_layer_ir]\n",
        "end_time = time.perf_counter()\n",
        "print(\n",
        "    f\"Inference finished. Inference time: {end_time-start_time:.3f} seconds, \"\n",
        "    f\"FPS: {1/(end_time-start_time):.2f}.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4b7f850",
      "metadata": {
        "tags": [
          "hide"
        ],
        "id": "a4b7f850"
      },
      "source": [
        "## 결과 시각화 [$\\Uparrow$](#목차:)\n",
        "\n",
        "원본 영상, 분할 결과, 배경이 제거된 원본 영상을 표시합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82f22737",
      "metadata": {
        "tags": [
          "hide"
        ],
        "id": "82f22737"
      },
      "outputs": [],
      "source": [
        "# Resize the network result to the image shape and round the values\n",
        "# to 0 (background) and 1 (foreground).\n",
        "# The network result has (1,1,512,512) shape. The `np.squeeze` function converts this to (512, 512).\n",
        "resized_result = np.rint(\n",
        "    cv2.resize(src=np.squeeze(result), dsize=(image.shape[1], image.shape[0]))\n",
        ").astype(np.uint8)\n",
        "\n",
        "# Create a copy of the image and set all background values to 255 (white).\n",
        "bg_removed_result = image.copy()\n",
        "bg_removed_result[resized_result == 0] = 255\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20, 7))\n",
        "ax[0].imshow(image)\n",
        "ax[1].imshow(resized_result, cmap=\"gray\")\n",
        "ax[2].imshow(bg_removed_result)\n",
        "for a in ax:\n",
        "    a.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c29ee84",
      "metadata": {
        "tags": [
          "hide"
        ],
        "id": "8c29ee84"
      },
      "source": [
        "### 배경 이미지 추가 [$\\Uparrow$](#목차:)\n",
        "\n",
        "분할 결과에서 모든 전경 픽셀의 값은 1이고 모든 배경 픽셀의 값은 0입니다. 배경 이미지를 다음과 같이 바꿉니다.\n",
        "\n",
        "- 새로운 '배경 이미지'를 로드합니다.\n",
        "- 원본 이미지와 동일한 크기로 이미지 크기를 조정합니다.\n",
        "- '배경_이미지'에서 크기가 조정된 분할 결과의 값이 1인 모든 픽셀(원본 이미지의 전경 픽셀)을 0으로 설정합니다.\n",
        "- 이전 단계의 'bg_removed_result'(전경 픽셀만 포함하는 원본 이미지 부분)를 '배경 이미지'에 추가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5628a0c",
      "metadata": {
        "tags": [
          "hide"
        ],
        "id": "f5628a0c"
      },
      "outputs": [],
      "source": [
        "BACKGROUND_FILE = \"https://storage.openvinotoolkit.org/repositories/openvino_notebooks/data/data/image/wall.jpg\"\n",
        "OUTPUT_DIR = \"output\"\n",
        "\n",
        "os.makedirs(name=OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "background_image = cv2.cvtColor(src=load_image(BACKGROUND_FILE), code=cv2.COLOR_BGR2RGB)\n",
        "background_image = cv2.resize(src=background_image, dsize=(image.shape[1], image.shape[0]))\n",
        "\n",
        "# Set all the foreground pixels from the result to 0\n",
        "# in the background image and add the image with the background removed.\n",
        "background_image[resized_result == 1] = 0\n",
        "new_image = background_image + bg_removed_result\n",
        "\n",
        "# Save the generated image.\n",
        "new_image_path = Path(f\"{OUTPUT_DIR}/{Path(IMAGE_URI).stem}-{Path(BACKGROUND_FILE).stem}.jpg\")\n",
        "cv2.imwrite(filename=str(new_image_path), img=cv2.cvtColor(new_image, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "# Display the original image and the image with the new background side by side\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(18, 7))\n",
        "ax[0].imshow(image)\n",
        "ax[1].imshow(new_image)\n",
        "for a in ax:\n",
        "    a.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Create a link to download the image.\n",
        "image_link = FileLink(new_image_path)\n",
        "image_link.html_link_str = \"<a href='%s' download>%s</a>\"\n",
        "display(\n",
        "    HTML(\n",
        "        f\"The generated image <code>{new_image_path.name}</code> is saved in \"\n",
        "        f\"the directory <code>{new_image_path.parent}</code>. You can also \"\n",
        "        \"download the image by clicking on this link: \"\n",
        "        f\"{image_link._repr_html_()}\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b11acf85",
      "metadata": {
        "tags": [
          "hide"
        ],
        "id": "b11acf85"
      },
      "source": [
        "## 참고문헌 [$\\Uparrow$](#목차:)\n",
        "\n",
        "* [PIP 설치 openvino-dev](https://github.com/openvinotoolkit/openvino/blob/releases/2021/3/docs/install_guides/pypi-openvino-dev.md)\n",
        "* [모델 변환 API](https://docs.openvino.ai/2023.0/openvino_docs_model_processing_introduction.html)\n",
        "* [U^2-Net](https://github.com/xuebinqin/U-2-Net)\n",
        "* U^2-Net 연구 논문: [U^2-Net: 핵심 개체 감지를 위한 중첩된 U-구조를 통한 심층 분석](https://arxiv.org/pdf/2005.09007.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7XLEDY1KbehU"
      },
      "id": "7XLEDY1KbehU",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "ae617ccb002f72b3ab6d0069d721eac67ac2a969e83c083c4321cfcab0437cd1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}