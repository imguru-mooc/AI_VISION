{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01412caf",
   "metadata": {},
   "source": [
    "# Hello 객체 감지\n",
    "\n",
    "OpenVINO™에서 객체 감지 모델을 사용하는 방법에 대한 매우 기본적인 소개입니다.\n",
    "\n",
    "[Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/)의 [horizontal-text-Detection-0001](https://docs.openvino.ai/2023.0/omz_models_model_horizontal_text_Detection_0001.html) 모델이 사용됩니다. . 이미지의 가로 텍스트를 감지하고 `[100, 5]` 형태의 데이터 덩어리를 반환합니다. 감지된 각 텍스트 상자는 `[x_min, y_min, x_max, y_max, conf]` 형식으로 저장됩니다.\n",
    "`(x_min, y_min)`은 왼쪽 상단 경계 상자 모서리의 좌표이고 `(x_max, y_max)`는 오른쪽 하단 경계 상자 모서리의 좌표이며 `conf`는 예측 클래스에 대한 신뢰도입니다.\n",
    "\n",
    "#### 내용의 테이블:\n",
    "- [수입](#Imports-Uparrow)\n",
    "- [모델 가중치 다운로드](#Download-model-weights-Uparrow)\n",
    "- [추론 장치 선택](#Select-inference-device-Uparrow)\n",
    "- [모델 로드](#Load-the-Model-Uparrow)\n",
    "- [이미지 로드](#Load-an-Image-Uparrow)\n",
    "- [추론하기](#Do-Inference-Uparrow)\n",
    "- [결과 시각화](#Visualize-Results-Uparrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1371bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install openvino package\n",
    "%pip install -q \"openvino>=2023.1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740bfdd8",
   "metadata": {},
   "source": [
    "## Imports [$\\Uparrow$](#Table-of-content:)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d7aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import openvino as ov\n",
    "from pathlib import Path\n",
    "\n",
    "# Fetch `notebook_utils` module\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\n",
    "    url='https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/utils/notebook_utils.py',\n",
    "    filename='notebook_utils.py'\n",
    ")\n",
    "\n",
    "from notebook_utils import download_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd379ea",
   "metadata": {},
   "source": [
    "## Download model weights [$\\Uparrow$](#Table-of-content:)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577d51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_dir = Path(\"./model\").expanduser()\n",
    "\n",
    "model_name = \"horizontal-text-detection-0001\"\n",
    "model_xml_name = f'{model_name}.xml'\n",
    "model_bin_name = f'{model_name}.bin'\n",
    "\n",
    "model_xml_path = base_model_dir / model_xml_name\n",
    "model_bin_path = base_model_dir / model_bin_name\n",
    "\n",
    "if not model_xml_path.exists():\n",
    "    model_xml_url = \"https://storage.openvinotoolkit.org/repositories/open_model_zoo/2022.3/models_bin/1/horizontal-text-detection-0001/FP32/horizontal-text-detection-0001.xml\"\n",
    "    model_bin_url = \"https://storage.openvinotoolkit.org/repositories/open_model_zoo/2022.3/models_bin/1/horizontal-text-detection-0001/FP32/horizontal-text-detection-0001.bin\"\n",
    "\n",
    "    download_file(model_xml_url, model_xml_name, base_model_dir)\n",
    "    download_file(model_bin_url, model_bin_name, base_model_dir)\n",
    "else:\n",
    "    print(f'{model_name} already downloaded to {base_model_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c5b81-2cf9-41a7-95ec-8170a33de965",
   "metadata": {},
   "source": [
    "## 추론 장치 선택 [$\\Uparrow$](#목차:)\n",
    "\n",
    "OpenVINO를 사용하여 추론을 실행하려면 드롭다운 목록에서 장치를 선택하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e674a148-58a6-4717-b0ef-73f7caa83956",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "core = ov.Core()\n",
    "device = widgets.Dropdown(\n",
    "    options=core.available_devices + [\"AUTO\"],\n",
    "    value='AUTO',\n",
    "    description='Device:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b48949",
   "metadata": {},
   "source": [
    "## 모델 로드 [$\\Uparrow$](#목차:)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99737c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = ov.Core()\n",
    "\n",
    "model = core.read_model(model=model_xml_path)\n",
    "compiled_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "input_layer_ir = compiled_model.input(0)\n",
    "output_layer_ir = compiled_model.output(\"boxes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705ce668",
   "metadata": {},
   "source": [
    "## 이미지 로드 [$\\Uparrow$](#목차:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1cfeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the image from the openvino_notebooks storage\n",
    "image_filename = download_file(\n",
    "    \"https://storage.openvinotoolkit.org/repositories/openvino_notebooks/data/data/image/intel_rnb.jpg\",\n",
    "    directory=\"data\"\n",
    ")\n",
    "\n",
    "# Text detection models expect an image in BGR format.\n",
    "image = cv2.imread(str(image_filename))\n",
    "\n",
    "# N,C,H,W = batch size, number of channels, height, width.\n",
    "N, C, H, W = input_layer_ir.shape\n",
    "\n",
    "# Resize the image to meet network expected input sizes.\n",
    "resized_image = cv2.resize(image, (W, H))\n",
    "\n",
    "# Reshape to the network input shape.\n",
    "input_image = np.expand_dims(resized_image.transpose(2, 0, 1), 0)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fcaba9",
   "metadata": {},
   "source": [
    "## 추론하기 [$\\Uparrow$](#목차:)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ca630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an inference request.\n",
    "boxes = compiled_model([input_image])[output_layer_ir]\n",
    "\n",
    "# Remove zero only boxes.\n",
    "boxes = boxes[~np.all(boxes == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dfac5d",
   "metadata": {},
   "source": [
    "## 결과 시각화 [$\\Uparrow$](#목차:)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each detection, the description is in the [x_min, y_min, x_max, y_max, conf] format:\n",
    "# The image passed here is in BGR format with changed width and height. To display it in colors expected by matplotlib, use cvtColor function\n",
    "def convert_result_to_image(bgr_image, resized_image, boxes, threshold=0.3, conf_labels=True):\n",
    "    # Define colors for boxes and descriptions.\n",
    "    colors = {\"red\": (255, 0, 0), \"green\": (0, 255, 0)}\n",
    "\n",
    "    # Fetch the image shapes to calculate a ratio.\n",
    "    (real_y, real_x), (resized_y, resized_x) = bgr_image.shape[:2], resized_image.shape[:2]\n",
    "    ratio_x, ratio_y = real_x / resized_x, real_y / resized_y\n",
    "\n",
    "    # Convert the base image from BGR to RGB format.\n",
    "    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Iterate through non-zero boxes.\n",
    "    for box in boxes:\n",
    "        # Pick a confidence factor from the last place in an array.\n",
    "        conf = box[-1]\n",
    "        if conf > threshold:\n",
    "            # Convert float to int and multiply corner position of each box by x and y ratio.\n",
    "            # If the bounding box is found at the top of the image, \n",
    "            # position the upper box bar little lower to make it visible on the image. \n",
    "            (x_min, y_min, x_max, y_max) = [\n",
    "                int(max(corner_position * ratio_y, 10)) if idx % 2 \n",
    "                else int(corner_position * ratio_x)\n",
    "                for idx, corner_position in enumerate(box[:-1])\n",
    "            ]\n",
    "\n",
    "            # Draw a box based on the position, parameters in rectangle function are: image, start_point, end_point, color, thickness.\n",
    "            rgb_image = cv2.rectangle(rgb_image, (x_min, y_min), (x_max, y_max), colors[\"green\"], 3)\n",
    "\n",
    "            # Add text to the image based on position and confidence.\n",
    "            # Parameters in text function are: image, text, bottom-left_corner_textfield, font, font_scale, color, thickness, line_type.\n",
    "            if conf_labels:\n",
    "                rgb_image = cv2.putText(\n",
    "                    rgb_image,\n",
    "                    f\"{conf:.2f}\",\n",
    "                    (x_min, y_min - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.8,\n",
    "                    colors[\"red\"],\n",
    "                    1,\n",
    "                    cv2.LINE_AA,\n",
    "                )\n",
    "\n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14476f74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(convert_result_to_image(image, resized_image, boxes, conf_labels=False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f0492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae617ccb002f72b3ab6d0069d721eac67ac2a969e83c083c4321cfcab0437cd1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
