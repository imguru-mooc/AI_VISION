{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PN9FvIx614"
      },
      "source": [
        "## 가져오기 및 설정\n",
        "이 MediaPipe 샘플을 실행하기 위한 기본 가져오기부터 시작해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxbHBsF-8Y_l"
      },
      "outputs": [],
      "source": [
        "!pip install -q mediapipe==0.10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a49D7h4TVmru"
      },
      "source": [
        "## 대화형 분할 모델 다운로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHXsuWDxpOj4"
      },
      "source": [
        "다음으로 해야 할 일은 이 데모에 사용될 대화형 분할 모델을 다운로드하는 것입니다. 이 경우 **ptm_512_hdt_ptm_woid** 모델을 사용하게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMjuVQiDYJKF"
      },
      "outputs": [],
      "source": [
        "#@title 여기에서 다운로드를 시작하세요.\n",
        "!wget -O model.tflite -q https://storage.googleapis.com/mediapipe-models/interactive_segmenter/magic_touch/float32/1/magic_touch.tflite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuf_ejsaKyjS"
      },
      "source": [
        "## 시각화 유틸리티"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO-KVe1-jlHl"
      },
      "source": [
        "Interactive Segmenter API를 더 잘 보여주기 위해 이 Colab에서 사용할 시각화 도구 세트를 만들었습니다. 선택한 항목에 대한 오버레이가 그려집니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gYTyXhTKy3H"
      },
      "outputs": [],
      "source": [
        "def _normalized_to_pixel_coordinates(\n",
        "    normalized_x: float, normalized_y: float, image_width: int,\n",
        "    image_height: int):\n",
        "  \"\"\"Converts normalized value pair to pixel coordinates.\"\"\"\n",
        "\n",
        "  # Checks if the float value is between 0 and 1.\n",
        "  def is_valid_normalized_value(value: float) -> bool:\n",
        "    return (value > 0 or math.isclose(0, value)) and (value < 1 or\n",
        "                                                      math.isclose(1, value))\n",
        "\n",
        "  if not (is_valid_normalized_value(normalized_x) and\n",
        "          is_valid_normalized_value(normalized_y)):\n",
        "    # TODO: Draw coordinates even if it's outside of the image bounds.\n",
        "    return None\n",
        "  x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
        "  y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
        "  return x_px, y_px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83PEJNp9yPBU"
      },
      "source": [
        "## 테스트 이미지 다운로드\n",
        "\n",
        "대화형 분할을 시연하려면 다음 코드를 사용하여 샘플 이미지를 다운로드할 수 있습니다.\n",
        "\n",
        "단일 이미지로 작업하는 동안 `IMAGE_FILENAMES` 배열에 저장할 이미지 모음을 다운로드할 수 있다는 점은 주목할 가치가 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzXuqyIBlXer"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "IMAGE_FILENAMES = ['cats_and_dogs.jpg']\n",
        "\n",
        "for name in IMAGE_FILENAMES:\n",
        "  url = f'https://storage.googleapis.com/mediapipe-assets/{name}'\n",
        "  urllib.request.urlretrieve(url, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8XRmapjySMN"
      },
      "source": [
        "## 다운로드한 이미지 미리보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu_q-Z03r-ed"
      },
      "source": [
        "대화형 분할기와 함께 사용하기 전에 테스트 이미지를 표시할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rjHk72-lmHX"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import math\n",
        "\n",
        "# Height and width that will be used by the model\n",
        "DESIRED_HEIGHT = 480\n",
        "DESIRED_WIDTH = 480\n",
        "\n",
        "# Performs resizing and showing the image\n",
        "def resize_and_show(image):\n",
        "  h, w = image.shape[:2]\n",
        "  if h < w:\n",
        "    img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))\n",
        "  else:\n",
        "    img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
        "  cv2_imshow(img)\n",
        "\n",
        "\n",
        "# Preview the image(s)\n",
        "images = {name: cv2.imread(name) for name in IMAGE_FILENAMES}\n",
        "for name, image in images.items():\n",
        "  print(name)\n",
        "  resize_and_show(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4r2_ePylIa"
      },
      "source": [
        "## 추론 실행 및 결과 시각화\n",
        "대화형 분할 MediaPipe 작업을 사용하여 추론을 실행하려면 모델을 사용하여 'InteractiveSegmenter'를 초기화해야 합니다. 이 예에서는 이미지의 배경과 전경을 분리하고 별도의 색상을 적용하여 각각의 독특한 영역이 존재하는 부분을 강조합니다. 여기의 대화형 분류기는 신뢰도에 따라 발견된 각 항목에 카테고리를 적용하는 카테고리 마스크를 사용합니다. 'RegionOfInterest'도 제공합니다.\n",
        "'segment' 메소드에 대한 인수입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl6ojNjl4i6o"
      },
      "outputs": [],
      "source": [
        "x = 0.68 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "y = 0.68 #@param {type:\"slider\", min:0, max:1, step:0.01}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl_Oiye4mUuo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "from mediapipe.tasks.python.components import containers\n",
        "\n",
        "\n",
        "BG_COLOR = (192, 192, 192) # gray\n",
        "MASK_COLOR = (255, 255, 255) # white\n",
        "\n",
        "RegionOfInterest = vision.InteractiveSegmenterRegionOfInterest\n",
        "NormalizedKeypoint = containers.keypoint.NormalizedKeypoint\n",
        "\n",
        "# Create the options that will be used for InteractiveSegmenter\n",
        "base_options = python.BaseOptions(model_asset_path='model.tflite')\n",
        "options = vision.ImageSegmenterOptions(base_options=base_options,\n",
        "                                       output_category_mask=True)\n",
        "\n",
        "# Create the interactive segmenter\n",
        "with vision.InteractiveSegmenter.create_from_options(options) as segmenter:\n",
        "\n",
        "  # Loop through demo image(s)\n",
        "  for image_file_name in IMAGE_FILENAMES:\n",
        "\n",
        "    # Create the MediaPipe image file that will be segmented\n",
        "    image = mp.Image.create_from_file(image_file_name)\n",
        "\n",
        "    # Retrieve the masks for the segmented image\n",
        "    roi = RegionOfInterest(format=RegionOfInterest.Format.KEYPOINT,\n",
        "                           keypoint=NormalizedKeypoint(x, y))\n",
        "    segmentation_result = segmenter.segment(image, roi)\n",
        "    category_mask = segmentation_result.category_mask\n",
        "\n",
        "    # Generate solid color images for showing the output segmentation mask.\n",
        "    image_data = image.numpy_view()\n",
        "    fg_image = np.zeros(image_data.shape, dtype=np.uint8)\n",
        "    fg_image[:] = MASK_COLOR\n",
        "    bg_image = np.zeros(image_data.shape, dtype=np.uint8)\n",
        "    bg_image[:] = BG_COLOR\n",
        "\n",
        "    condition = np.stack((category_mask.numpy_view(),) * 3, axis=-1) > 0.1\n",
        "    output_image = np.where(condition, fg_image, bg_image)\n",
        "\n",
        "    # Draw a white dot with black border to denote the point of interest\n",
        "    thickness, radius = 6, -1\n",
        "    keypoint_px = _normalized_to_pixel_coordinates(x, y, image.width, image.height)\n",
        "    cv2.circle(output_image, keypoint_px, thickness + 5, (0, 0, 0), radius)\n",
        "    cv2.circle(output_image, keypoint_px, thickness, (255, 255, 255), radius)\n",
        "\n",
        "    print(f'Segmentation mask of {image_file_name}:')\n",
        "    resize_and_show(output_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RxsX2CjJbfo"
      },
      "source": [
        "이제 이미지의 전경과 배경을 분리하는 방법을 알았으므로 한 단계 더 나아가 Google 행아웃에서 제공하는 것과 유사한 효과를 위해 배경을 흐리게 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciCGwCQ3gNDc"
      },
      "outputs": [],
      "source": [
        "# Blur the image background based on the segmentation mask.\n",
        "\n",
        "# Create the segmenter\n",
        "with python.vision.InteractiveSegmenter.create_from_options(options) as segmenter:\n",
        "\n",
        "  # Loop through available image(s)\n",
        "  for image_file_name in IMAGE_FILENAMES:\n",
        "\n",
        "    # Create the MediaPipe Image\n",
        "    image = mp.Image.create_from_file(image_file_name)\n",
        "\n",
        "    # Retrieve the category masks for the image\n",
        "    roi = RegionOfInterest(format=RegionOfInterest.Format.KEYPOINT,\n",
        "                           keypoint=NormalizedKeypoint(x, y))\n",
        "    segmentation_result = segmenter.segment(image, roi)\n",
        "    category_mask = segmentation_result.category_mask\n",
        "\n",
        "    # Convert the BGR image to RGB\n",
        "    image_data = cv2.cvtColor(image.numpy_view(), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Apply effects\n",
        "    blurred_image = cv2.GaussianBlur(image_data, (55,55), 0)\n",
        "    condition = np.stack((category_mask.numpy_view(),) * 3, axis=-1) > 0.1\n",
        "    output_image = np.where(condition, image_data, blurred_image)\n",
        "\n",
        "    # Draw a white dot with black border to denote the point of interest\n",
        "    thickness, radius = 6, -1\n",
        "    keypoint_px = _normalized_to_pixel_coordinates(x, y, image.width, image.height)\n",
        "    cv2.circle(output_image, keypoint_px, thickness + 5, (0, 0, 0), radius)\n",
        "    cv2.circle(output_image, keypoint_px, thickness, (255, 255, 255), radius)\n",
        "\n",
        "    print(f'Blurred background of {image_file_name}:')\n",
        "    resize_and_show(output_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBYU6waBmq3R"
      },
      "source": [
        "(배경 흐림 대신) 오버레이 색상으로 선택한 개체를 강조 표시하는 또 다른 시각화 이미지를 생성해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szFMEFuymrHd"
      },
      "outputs": [],
      "source": [
        "OVERLAY_COLOR = (100, 100, 0) # cyan\n",
        "\n",
        "# Create the segmenter\n",
        "with python.vision.InteractiveSegmenter.create_from_options(options) as segmenter:\n",
        "\n",
        "  # Loop through available image(s)\n",
        "  for image_file_name in IMAGE_FILENAMES:\n",
        "\n",
        "    # Create the MediaPipe Image\n",
        "    image = mp.Image.create_from_file(image_file_name)\n",
        "\n",
        "    # Retrieve the category masks for the image\n",
        "    roi = RegionOfInterest(format=RegionOfInterest.Format.KEYPOINT,\n",
        "                           keypoint=NormalizedKeypoint(x, y))\n",
        "    segmentation_result = segmenter.segment(image, roi)\n",
        "    category_mask = segmentation_result.category_mask\n",
        "\n",
        "    # Convert the BGR image to RGB\n",
        "    image_data = cv2.cvtColor(image.numpy_view(), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Create an overlay image with the desired color (e.g., (255, 0, 0) for red)\n",
        "    overlay_image = np.zeros(image_data.shape, dtype=np.uint8)\n",
        "    overlay_image[:] = OVERLAY_COLOR\n",
        "\n",
        "    # Create the condition from the category_masks array\n",
        "    alpha = np.stack((category_mask.numpy_view(),) * 3, axis=-1) > 0.1\n",
        "\n",
        "    # Create an alpha channel from the condition with the desired opacity (e.g., 0.7 for 70%)\n",
        "    alpha = alpha.astype(float) * 0.7\n",
        "\n",
        "    # Blend the original image and the overlay image based on the alpha channel\n",
        "    output_image = image_data * (1 - alpha) + overlay_image * alpha\n",
        "    output_image = output_image.astype(np.uint8)\n",
        "\n",
        "    # Draw a white dot with black border to denote the point of interest\n",
        "    thickness, radius = 6, -1\n",
        "    keypoint_px = _normalized_to_pixel_coordinates(x, y, image.width, image.height)\n",
        "    cv2.circle(output_image, keypoint_px, thickness + 5, (0, 0, 0), radius)\n",
        "    cv2.circle(output_image, keypoint_px, thickness, (255, 255, 255), radius)\n",
        "\n",
        "    print(f'{image_file_name}:')\n",
        "    resize_and_show(output_image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vwCLST-6UWah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2BkGgLknSPi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "fuf_ejsaKyjS"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}