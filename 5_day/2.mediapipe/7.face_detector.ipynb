{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_cQX8dWu4Dv"
      },
      "source": [
        "# MediaPipe 작업을 통한 얼굴 감지\n",
        "\n",
        "이 노트북은 MediaPipe Tasks Python API를 사용하여 이미지에서 얼굴을 감지하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PN9FvIx614"
      },
      "source": [
        "## 준비\n",
        "\n",
        "MediaPipe 설치부터 시작해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxbHBsF-8Y_l"
      },
      "outputs": [],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a49D7h4TVmru"
      },
      "source": [
        "그런 다음 기성 모델을 다운로드하십시오. 사용할 수 있는 더 많은 얼굴 감지 모델을 보려면 [MediaPipe 문서](https://developers.google.com/mediapipe/solutions/vision/face_Detector#models)를 확인하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMjuVQiDYJKF"
      },
      "outputs": [],
      "source": [
        "!wget -q -O detector.tflite -q https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89BlskiiyGDC"
      },
      "source": [
        "## 시각화 유틸리티"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLHhoIkkWYLQ"
      },
      "source": [
        "Face Detector API를 더 잘 보여주기 위해 이 Colab에서 사용할 시각화 도구 세트를 만들었습니다. 그러면 감지된 얼굴 주위에 경계 상자가 그려지고 얼굴에서 감지된 특정 지점 위에 마커가 그려집니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4aPO-hvbw3r"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, Union\n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "MARGIN = 10  # pixels\n",
        "ROW_SIZE = 10  # pixels\n",
        "FONT_SIZE = 1\n",
        "FONT_THICKNESS = 1\n",
        "TEXT_COLOR = (255, 0, 0)  # red\n",
        "\n",
        "\n",
        "def _normalized_to_pixel_coordinates(\n",
        "    normalized_x: float, normalized_y: float, image_width: int,\n",
        "    image_height: int) -> Union[None, Tuple[int, int]]:\n",
        "  \"\"\"Converts normalized value pair to pixel coordinates.\"\"\"\n",
        "\n",
        "  # Checks if the float value is between 0 and 1.\n",
        "  def is_valid_normalized_value(value: float) -> bool:\n",
        "    return (value > 0 or math.isclose(0, value)) and (value < 1 or\n",
        "                                                      math.isclose(1, value))\n",
        "\n",
        "  if not (is_valid_normalized_value(normalized_x) and\n",
        "          is_valid_normalized_value(normalized_y)):\n",
        "    # TODO: Draw coordinates even if it's outside of the image bounds.\n",
        "    return None\n",
        "  x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
        "  y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
        "  return x_px, y_px\n",
        "\n",
        "\n",
        "def visualize(\n",
        "    image,\n",
        "    detection_result\n",
        ") -> np.ndarray:\n",
        "  \"\"\"Draws bounding boxes and keypoints on the input image and return it.\n",
        "  Args:\n",
        "    image: The input RGB image.\n",
        "    detection_result: The list of all \"Detection\" entities to be visualize.\n",
        "  Returns:\n",
        "    Image with bounding boxes.\n",
        "  \"\"\"\n",
        "  annotated_image = image.copy()\n",
        "  height, width, _ = image.shape\n",
        "\n",
        "  for detection in detection_result.detections:\n",
        "    # Draw bounding_box\n",
        "    bbox = detection.bounding_box\n",
        "    start_point = bbox.origin_x, bbox.origin_y\n",
        "    end_point = bbox.origin_x + bbox.width, bbox.origin_y + bbox.height\n",
        "    cv2.rectangle(annotated_image, start_point, end_point, TEXT_COLOR, 3)\n",
        "\n",
        "    # Draw keypoints\n",
        "    for keypoint in detection.keypoints:\n",
        "      keypoint_px = _normalized_to_pixel_coordinates(keypoint.x, keypoint.y,\n",
        "                                                     width, height)\n",
        "      color, thickness, radius = (0, 255, 0), 2, 2\n",
        "      cv2.circle(annotated_image, keypoint_px, thickness, color, radius)\n",
        "\n",
        "    # Draw label and score\n",
        "    category = detection.categories[0]\n",
        "    category_name = category.category_name\n",
        "    category_name = '' if category_name is None else category_name\n",
        "    probability = round(category.score, 2)\n",
        "    result_text = category_name + ' (' + str(probability) + ')'\n",
        "    text_location = (MARGIN + bbox.origin_x,\n",
        "                     MARGIN + ROW_SIZE + bbox.origin_y)\n",
        "    cv2.putText(annotated_image, result_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
        "                FONT_SIZE, TEXT_COLOR, FONT_THICKNESS)\n",
        "\n",
        "  return annotated_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83PEJNp9yPBU"
      },
      "source": [
        "## 테스트 이미지 다운로드\n",
        "\n",
        "얼굴 감지를 시연하기 위해 다음 코드를 사용하여 샘플 이미지를 다운로드할 수 있습니다. 크레딧: https://pixabay.com/photos/brother-sister-girl-family-boy-977170/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzXuqyIBlXer"
      },
      "outputs": [],
      "source": [
        "!wget -q -O image.jpg https://i.imgur.com/Vu2Nqwb.jpg\n",
        "\n",
        "IMAGE_FILE = 'image.jpg'\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread(IMAGE_FILE)\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAFQm3HHi5OG"
      },
      "source": [
        "선택적으로 컴퓨터에서 자신만의 이미지를 업로드할 수 있습니다. 이렇게 하려면 다음 코드 셀의 주석 처리를 제거하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gwip05yi6lV"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for filename in uploaded:\n",
        "#   content = uploaded[filename]\n",
        "#   with open(filename, 'wb') as f:\n",
        "#     f.write(content)\n",
        "\n",
        "# if len(uploaded.keys()):\n",
        "#   IMAGE_FILE = next(iter(uploaded))\n",
        "#   print('Uploaded file:', IMAGE_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4r2_ePylIa"
      },
      "source": [
        "## 추론 실행 및 결과 시각화\n",
        "\n",
        "마지막 단계는 선택한 이미지에서 얼굴 감지를 실행하는 것입니다. 여기에는 FaceDetector 개체 생성, 이미지 로드, 감지 실행, 마지막으로 시각화를 통해 이미지를 표시하는 선택적 단계가 포함됩니다.\n",
        "\n",
        "이 솔루션이 지원하는 구성 옵션에 대해 자세히 알아보려면 [MediaPipe 문서](https://developers.google.com/mediapipe/solutions/vision/face_Detector/python)를 확인하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl_Oiye4mUuo"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Import the necessary modules.\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "\n",
        "# STEP 2: Create an FaceDetector object.\n",
        "base_options = python.BaseOptions(model_asset_path='detector.tflite')\n",
        "options = vision.FaceDetectorOptions(base_options=base_options)\n",
        "detector = vision.FaceDetector.create_from_options(options)\n",
        "\n",
        "# STEP 3: Load the input image.\n",
        "image = mp.Image.create_from_file(IMAGE_FILE)\n",
        "\n",
        "# STEP 4: Detect faces in the input image.\n",
        "detection_result = detector.detect(image)\n",
        "\n",
        "# STEP 5: Process the detection result. In this case, visualize it.\n",
        "image_copy = np.copy(image.numpy_view())\n",
        "annotated_image = visualize(image_copy, detection_result)\n",
        "rgb_annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
        "cv2_imshow(rgb_annotated_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNJq-ygtZX7J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}